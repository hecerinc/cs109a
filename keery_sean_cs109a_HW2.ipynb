{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Homework 2\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, September 21st, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `IPython` notebook as well as the data file from Vocareum and complete locally.\n",
    "\n",
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW2.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn as sk\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keery, Sean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS 109a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Rick Farmer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Inside the Models in Scikit-learn\n",
    "\n",
    "In this problem, we will be implementing K-Nearest Neighbour and simple linear regression for predicting a quantitative variable. We will compare the performance of our implementation with those of Scikit-learn (``sklearn``).\n",
    "\n",
    "The datasets required for this problem is in the ``dataset`` directory. Each file in the ``dataset`` directory contains a one-dimensional data set, with the first column containing the independent variable X, and the second column containing the dependent variable Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Implement the models by hand\n",
    "In this part you **may not** use ``sklearn`` for any task.\n",
    "\n",
    "In the following, you may use ``numpy`` arrays instead of ``pandas`` dataframes.\n",
    "\n",
    "- Implement a funtion ``split``, which satifies:\n",
    "    - input: an ``nx2`` dataframe ``data``, a float ``m``\n",
    "    - return: an ``nx2`` dataframe ``train`` and an ``nx2`` dataframe ``test``, consisting of ``m`` percent and ``100 - m`` percent of the data, respectively.\n",
    "\n",
    "\n",
    "- Implement K-Nearest Neighbour for predicting a quantitative variable. That is, write a function, ``knn_predict``, that satisfies:\n",
    "    - input: an integer ``k``, an ``n x 2`` dataframe training set ``train``, an ``n x 1`` dataframe testing set ``test``\n",
    "    - return: an ``nx2`` dataframe, whose first column is that of ``test`` and whose second column is the predicted values.\n",
    "\n",
    "\n",
    "\n",
    "- Implement linear regression for predicting a quantitative variable. That is, write a function ``linear_reg_fit`` that satisfies:\n",
    "    - input: an ``nx2`` dataframe training set ``train``\n",
    "    - return: the coefficients of the linear regression model - a float ``slope`` and a float ``intercept``.\n",
    "    \n",
    "    \n",
    "- Write a function ``linear_reg_predict`` that satisfies:\n",
    "    - input: an ``nx1`` dataframe testing set ``test``, as well as the coefficients of the linear regression model\n",
    "    - return: an ``nx2`` dataframe, whose first column is that of ``test`` and whose second column is the predicted values.\n",
    "    \n",
    "    \n",
    "- Implement a function ``score`` that satisfies:\n",
    "    - input: an ``nx2`` dataframe ``predicted``, an ``nx2`` dataframe ``actual`` \n",
    "    - return: R^2 coefficient of the fit of the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement a funtion split, which satifies:\n",
    "# input: an nx2 dataframe data, a float m\n",
    "# return: an nx2 dataframe train and an nx2 dataframe test, consisting of m percent and 100 - m percent of the data, respectively.\n",
    "def split(data,m):\n",
    "    #find the number of records dataframe\n",
    "    length = data.shape[0]\n",
    "    #build a list of integer indices for records in dataframe\n",
    "    indices = range(length)\n",
    "    #randomly shuffle the indices\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    #convert m to float for division\n",
    "    m = float(m)\n",
    "    #print m\n",
    "    \n",
    "    #create percentages\n",
    "    train_percent = m/100\n",
    "    #print train_percent\n",
    "    test_percent = 1-train_percent\n",
    "    \n",
    "    #take percentage of the shuffled list of indices for training\n",
    "    train_indices = indices[0:int(length * train_percent)]\n",
    "    #take the remainder the shuffled list of indices for testing\n",
    "    test_indices = indices[int(length * test_percent):]\n",
    "    \n",
    "    #get the records for the training indices\n",
    "    train = data.iloc[train_indices, :]\n",
    "    #get the records for the testing indices\n",
    "    test = data.iloc[test_indices, :]\n",
    "    \n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement K-Nearest Neighbour for predicting a quantitative variable. That is, write a function, knn_predict, that satisfies:\n",
    "# input: an integer k, an n x 2 dataframe training set train, an n x 1 dataframe testing set test\n",
    "# return: an nx2 dataframe, whose first column is that of test and whose second column is the predicted values.\n",
    "def knn_predict(k,train,test):\n",
    "    #create dataframe with just biometric and disease subtype info\n",
    "    biometric_df = train[['marker_1', 'marker_2']]\n",
    "    \n",
    "    #we'll build a list of the nearest neighbour for each of our test points\n",
    "    nearest_neighbours = []\n",
    "    \n",
    "    #iterate through the rows in the test data\n",
    "    for index, test_row in test.iterrows():\n",
    "        #for each test patient, store the distance between all training points and test point in an series\n",
    "        distances = ((train['marker_1'] - test_row['marker_1'])**2 \n",
    "                     + (train['marker_2'] - test_row['marker_2'])**2)\n",
    "        \n",
    "        #find the row label of the training point that is the closest to the test point\n",
    "        nearest = distances.idxmin()\n",
    "        \n",
    "        #add the nearest neighbour for the current test point to our list\n",
    "        nearest_neighbours.append(nearest)\n",
    "        \n",
    "    #get the disease subtype of the closest neighbour of each test point\n",
    "    predicted_subtypes = train.loc[nearest_neighbours]['subtype'].values\n",
    "    \n",
    "    return predicted_subtypes\n",
    "    \n",
    "    #create response dataframe\n",
    "    knn.response(columns=['test_value','predicted_value'])\n",
    "    \n",
    "    return knn_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement linear regression for predicting a quantitative variable. That is, write a function linear_reg_fit that satisfies:\n",
    "# input: an nx2 dataframe training set train\n",
    "# return: the coefficients of the linear regression model - a float slope and a float intercept.\n",
    "def linear_reg_fit(train):\n",
    "    \n",
    "    retun lr_slope,lr_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function linear_reg_predict that satisfies:\n",
    "# input: an nx1 dataframe testing set test, as well as the coefficients of the linear regression model\n",
    "# return: an nx2 dataframe, whose first column is that of test and whose second column is the predicted values.\n",
    "def linear_reg_predict(test,lr_slope,lr_intercept):\n",
    "    lr.response(columns=['test_value','predicted_value'])\n",
    "    \n",
    "    return lr_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement a function score that satisfies:\n",
    "# input: an nx2 dataframe predicted, an nx2 dataframe actual\n",
    "# return: R^2 coefficient of the fit of the predicted values.\n",
    "def score(df_predicted,df_actual):\n",
    "    #subtract the array of predicted subtypes and the array of true subtypes\n",
    "    comparison = df_predicted - df_actual\n",
    "    \n",
    "    #when the predicted value is different from the true value, that entry is non-zero\n",
    "    #we set all non-zero entries (wrong predictions) to 1\n",
    "    comparison[comparison != 0] = 1\n",
    "    \n",
    "    #the total number of wrong predictions is the sum of the array (where entries have a 1\n",
    "    #for wrong and 0 for right)\n",
    "    total_wrong = comparison.sum()\n",
    "    \n",
    "    right_percent = (len(comparison) - total_wrong) / (len(comparison) * 1.0)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Compare with ``sklearn``\n",
    "\n",
    "- Load the contents of ``dataset_1_full.txt`` into a ``pandas`` dataframe, or ``numpy`` array. \n",
    "\n",
    "\n",
    "- Use your functions from Part (a) to split the data into training and testing sets (70-30). Evaluate how KNN and linear regression each perform on this dataset.\n",
    "\n",
    "\n",
    "- Use ``sklearn`` to split the data into training and testing sets (70-30). Use ``sklearn`` to evaluate how KNN and linear regression each perform on this dataset.\n",
    "\n",
    "\n",
    "- Use Python's ``time`` library to measure how well your implementations compare with that of ``sklearn``. What can you do (algorithmically or codewise) to make your implementation faster or more efficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177418</td>\n",
       "      <td>1.401178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573076</td>\n",
       "      <td>3.489890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503775</td>\n",
       "      <td>1.684924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594027</td>\n",
       "      <td>3.898209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.335754</td>\n",
       "      <td>2.878410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.177418  1.401178\n",
       "1  0.573076  3.489890\n",
       "2  0.503775  1.684924\n",
       "3  0.594027  3.898209\n",
       "4  0.335754  2.878410"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the contents of dataset_1_full.txt\n",
    "#read data into pandas df\n",
    "df = pd.read_csv('dataset/dataset_1_full.txt')\n",
    "\n",
    "#size of data frame\n",
    "print 'number of rows:', df.shape[0]\n",
    "\n",
    "#print first 5 rows of dataframe\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.169095</td>\n",
       "      <td>1.887931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.888477</td>\n",
       "      <td>3.754016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.398479</td>\n",
       "      <td>3.210031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.978806</td>\n",
       "      <td>5.561542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.411623</td>\n",
       "      <td>0.108954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y\n",
       "377  0.169095  1.887931\n",
       "157  0.888477  3.754016\n",
       "387  0.398479  3.210031\n",
       "140  0.978806  5.561542\n",
       "354  0.411623  0.108954"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use functions from Part (a) to split the data into training and testing sets (70-30)\n",
    "train,test=split(df,70)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.463692748776\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to evaluate how KNN and linear regression each perform on this dataset.\n",
    "# # put data in format usable by sklearn\n",
    "#  X = [[0], [1], [2], [3]]\n",
    "#  y = [0, 0, 1, 1]\n",
    "x_train = train.as_matrix(columns=['x'])\n",
    "# print x_train\n",
    "y_train = train['y'].values\n",
    "# print y_train\n",
    "x_test = test.as_matrix(columns=['x'])\n",
    "y_test = test['y'].values\n",
    "\n",
    "#set number of nearest neighbouts\n",
    "k=5\n",
    "\n",
    "# create knn model\n",
    "neighbours=KNN(n_neighbors=k)\n",
    "\n",
    "#set parameter of model\n",
    "neighbours.fit(x_train,y_train)\n",
    "\n",
    "#predict y responses\n",
    "predicted_y=neighbours.predict(x_test)\n",
    "\n",
    "#score\n",
    "r=neighbours.score(x_test,y_test)\n",
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Python's time library to measure how well your implementations compare with that of sklearn. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What can you do (algorithmically or codewise) to make your implementation faster or more efficient?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Handling Missing Data\n",
    "\n",
    "In this problem, we will be handling the problem of datasets with missing values. Clearly, we cannot simply remove entire rows or columns that contain missing values. In this problem, we explore two different ways to fill in missing values.\n",
    "\n",
    "The datasets required for this problem is in the ``dataset`` directory. Each file in the ``dataset`` directory contains a one-dimensional data set, with the first column containing the independent variable X, and the second column containing the dependent variable Y.\n",
    "\n",
    "The files ``dataset_1_missing.txt`` to ``dataset_6_missing.txt`` contains rows that are missing their y-values, where as ``dataset_1_full.txt`` to ``dataset_6_full.txt`` contain datasets with all y-values correctly filled in.\n",
    "\n",
    "In this problem, you **may not** use ``sklearn`` or build-in ``pandas`` functions to **directly fill in missing values**. Usage of these libraries/pakcages for related tasks is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Model Based Data Imputation\n",
    "\n",
    "- Describe in detail how predictive models for data (like KNN and simple linear regression) can be used to fill in missing values in a data set.\n",
    "\n",
    "\n",
    "- Implement your scheme. That is, write code (preferably a function ``fill`` or two functions ``fill_knn``, ``fill_lin_reg``), which takes an ``n x 2`` dataframe or array with values missing in the 2nd column and fills in these values using KNN and linear regression. \n",
    "\n",
    "\n",
    "- You need to, also, write code to evaluate the quality of the values you've filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Which Model is Better?\n",
    "\n",
    "- For datasets ``dataset_1_missing.txt`` to ``dataset_6_missing.txt``, compare the result of filling in the missing values using KNN and linear regression, using both the R^2 coefficient as well as data visualization (the correct y-values are contained in ``dataset_1_full.txt`` to ``dataset_6_full.txt``).. \n",
    "\n",
    "\n",
    "- Use your analysis to form conjectures regarding the conditions under which KNN performs better than linear regression, under which linear regression performs better than KNN and under which both perform equally (well or poorly). Explain in detail exactly what might cause each model to fail or perform well. \n",
    "\n",
    "\n",
    "\n",
    "- Using ``dataset_1_missing.txt``, explain the impact of the choice of $k$ on the performance of KNN. \n",
    "\n",
    "\n",
    "Use numerical analysis and data visualization to support every part of your argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Is the Best (Linear Model) Good Enough?\n",
    "\n",
    "In this problem, we will specifically look at conditions under which linear regression excels or fails.\n",
    "\n",
    "The datasets required for this problem is in the ``dataset`` directory. Each file in the ``dataset`` directory contains a one-dimensional data set, with the first column containing the independent variable X, and the second column containing the dependent variable Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Introduction to Residual Plots\n",
    "\n",
    "- Read ``dataset_1_full.txt``. Visualize the dataset and make some initial observations.\n",
    "\n",
    "\n",
    "- For this data set, what can you say about the following linear fits: \n",
    "\n",
    "    1. slope = 0.4, intercept = 0.2\n",
    "    2. slope = 0.4, intercept = 4\n",
    "    3. linear regression model\n",
    "\n",
    "\n",
    "- In each case, visualize the fit, compute the residuals, and make a residual plot of predicted values along with  residuals, as well as a residual histogram. What do these plots reveal?  \n",
    "\n",
    "\n",
    "- Calculate the R^2 coefficient for all three fits. What do the erors reveal? How do they compare to the residual plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): What do Residual Plots Reveal?\n",
    "\n",
    "- Read datasets ``dataset_2_full.txt`` through ``dataset_6_full.txt``. In each case, visualize the fit, compute the residuals, and make a residual plot of predicted values along with  residuals, as well as a residual histogram. What do these plots reveal about the fit of the model? \n",
    "\n",
    "\n",
    "- Calculate the R^2 coefficient each fit. What do the erors reveal? How do they compare to the residual plots?\n",
    "\n",
    "\n",
    "- Based on your analysis, form conjectures regarding the precise relationship between the residual plots and the fit of the linear regression model. Conjecture on the precise conditions under which linear regression model is an appropriate model for a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Combining Random Variables\n",
    "\n",
    "This problem, we explore the distirbution of random variables that result from combining other random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Adding Two Uniformly Distributed Variables\n",
    "\n",
    "Consider the independent random variables $X\\sim U(0, 1)$ and $Y\\sim U(0, 1)$. Let $Z$ be the random variable $Z = X + Y$. \n",
    "\n",
    "What is the distribution of $Z$ (give the pdf for Z)? You should fully explain and support your conlusion. \n",
    "\n",
    "**Hint:** your solution can be a combination of experimentation, empirical evidence and/or algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Adding Multiple Uniformly Distributed Variables\n",
    "\n",
    "Consider three independent random variables $X_1, X_2, X_3 \\sim U(0, 1)$. Let $Z$ be the random variable $Z = X_1 + X_2 + X_3$. \n",
    "\n",
    "What is the distribution of $Z$? What if you add 10 or 12 independent (standard) uniformly distributed variables? Conjecture on the distribution of \n",
    "$$\n",
    "Z = \\lim_{n\\to \\infty} \\sum_{i=1}^n X_i\n",
    "$$\n",
    "where $\\left\\{X_i \\right\\}$ are independent (standard) uniformly distributed variables.\n",
    "\n",
    "**Hint:** your solution can be a combination of experimentation, empirical evidence and/or algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Combining Normally Distributed Variables\n",
    "\n",
    "Consider the independent random variables $X\\sim \\mathcal{N}(0, 1)$ and $Y\\sim \\mathcal{N}(0, 1)$. Let $Z$ be the random variable $Z = X + Y$. \n",
    "\n",
    "What is the distribution of $Z$ (give the pdf for Z)? You should fully explain and support your conlusion. \n",
    "\n",
    "**Hint:** use properties of expected value and some experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d): Product of Normally Distributed Variables\n",
    "\n",
    "Is the product of two normally distributed variables a normally distributed variable? You should fully explain and support your conlusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
